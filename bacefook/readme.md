# Bacefook Backend Assignment

![Bacefook Logo](images/bacefook_logo.png)

This repository contains the solution for the Zentry backend assignment. It uses Bun as the main JavaScript runtime. Please install Bun to run this project.

Performance was measured on a 2021 MacBook Pro (M1 Pro, 16GB RAM, 512GB SSD) running macOS 15.5 with Bun 1.2.18.

## Components

This project consists of six components:

### 1. events-producer

This component uses the provided generator to feed data into a Kafka topic with a single partition, achieving a throughput of ~70-100k messages per second with `count = 5` as the input for the events generator.

### 2. backend-processor

This component reads events from the Kafka topic, processes them to construct a relationship graph, and updates MongoDB with the most recent state of the graph in every batch. It also stores all observed events in MongoDB, which allows other sub-services to replay and process the data for analytics.

The relationship graph is designed to be idempotent; duplicate events will not corrupt the state of the graph, provided that the events are ordered (hence the single partition in the Kafka topic). The processor achieves a throughput of around 40k messages per second (~200k messages per 5 seconds).

### 3. backend-api

This component serves the following API endpoints (default port: `3000`):

- `GET /analytics/network`
- `GET /analytics/leaderboard`
- `GET /users/{name}/top-friends`
- `GET /users/{name}/friends`
- `GET /meta/snapshots`
- `GET /meta/users`

> Note: `GET /meta/snapshots` and `GET /meta/users` are provided for metadata purposes and are **not** part of the assignment requirements.

On startup, this service also acts as a replayer for processing events stored in MongoDB for analytical purposes. It retrieves all events from MongoDB in batches of 100,000 records and saves them to disk to prevent memory exhaustion. It then uses these on-disk event chunks to feed the relationship graph and generate snapshot files for every 5 seconds of the records' creation times.

This process is intended to always be up-to-date with MongoDB's state. However, due to time constraints, it currently only syncs with the database on startup.

From observation, it appears that this service is capable of retrieving and ingesting around 100k records per second.

This component does not yet serve:

- User's referral timeseries graph for any given time range.
- User's referral count for any given time range.
- User's friends count timeseries graph for any given time range.
- User's friends count for any given time range.

The author believes that these four features can be implemented together if attempted.

### 4. frontend

![Frontend 1](images/frontend_1.png)

![Frontend 2](images/frontend_2.png)

![Frontend 3](images/frontend_3.png)

This frontend features a total user count on its header and two pages: analytics and user profile.

On the analytics page, you can query by username for a relationship graph showing the friends of the queried user, the users they have referred, and the user that referred the queried user. On this page, you can also query leaderboards of network strength and referral points gained by time range.

On the user profile page, you can query by username to retrieve their top 3 influential friends and their friends, along with those users' friend counts, referral counts, and referral points.

Due to time constraints, the time series requirements on the user profile page have not been implemented.

#### 5. Redpanda Broker

Used as the Kafka broker, it is fed with events generated by the events generator for playback ability and uses one partition to guarantee global order.

#### 6. MongoDB

Stores the most recent state of the relationship graph and all events retrieved from the Kafka broker, which can then be used for playback to process data for analytical purposes.

## Architecture

The system is composed of the following high-level data flow:

```mermaid
graph TD
    A[Events Producer] -->|Kafka topic: bacefook-relationship-events-topic| B[Backend Processor]
    B -->|State updates - relationship_users| D[MongoDB]
    B -->|Raw events - relationship_events| D
    B -->|Kafka offset tracking - kafka_offsets| D
    D -->|Replay events on startup| C[Backend API]
    C -->|Graph and snapshots| E[Frontend]
```

### Summary

1.  **Event Generation**  
    The `events-producer` feeds synthetic user events (register, referral, addfriend, unfriend) into a single-partition Kafka topic.
2.  **Processing & Storage**  
    The `backend-processor` consumes these events in order, builds a relationship graph in memory, updates MongoDB with user states, and stores the raw events for later replay.
3.  **Analytics Replay**  
    The `backend-api` service replays stored events from MongoDB into a graph on startup, creates 5-second interval snapshots, and exposes both analytical endpoints and the most recent state of users.
4.  **Frontend Visualization**  
    The `frontend` visualizes the data from `backend-api`, including network graphs, leaderboards, and user metrics.

## How to Run

A Docker Compose file is included in this directory. Run `docker-compose up -d` to create the following services:

- **Redpanda**: A Kafka broker on port `19092`.
- **Redpanda Console**: A web UI for Redpanda at `http://localhost:8080`. The `bacefook-relationship-events-topic` is automatically created on startup.
- **MongoDB**: An instance is created and available at port `27017`.

Please see the README in each component's folder to continue the startup process for each component.

## What Has Been Accomplished

- Kafka data pipeline for global event ordering and the ability to replay in case of a crash or failure to sync with the database.
- The processor can process events, satisfying the required throughput.
- Display a network of relationships for a given user.
- Display a `network strength` ranking in a leaderboard-like list for any time range.
- Display a `referral points` ranking in a leaderboard-like list for any time range.
- Display a user's top 3 `influential friends`.
- Display a paginated list of a user's friends.

## What Hasn't Been Accomplished

- User's referral timeseries graph for any given time range.
- User's referral count for any given time range.
- User's friends count timeseries graph for any given time range.
- User's friends count for any given time range.
- The backend API only syncs with the database on startup and is not always up-to-date for the analytics page.
